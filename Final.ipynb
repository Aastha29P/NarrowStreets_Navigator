{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "021ea111-d561-4868-941f-9f9317767ae8",
   "metadata": {},
   "source": [
    "# Fine Tuning process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e49122-5a26-4d0d-a5f2-2f7c9b85a2cf",
   "metadata": {},
   "source": [
    "### We'll break down the process into the following sections:\n",
    "\n",
    "#### 1. Collect and Prepare Domain-Specific Training Data\n",
    "#### 2. Fine-Tune a Base Language Model (LLM) for Your Specific Use Case\n",
    "#### 3. Implement Evaluation Metrics for Model Performance\n",
    "#### 4. Document the Fine-Tuning Process and Results \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feb1b92-d19f-498f-bff2-b42294363b3f",
   "metadata": {},
   "source": [
    "## 1. Collect and Prepare Domain-Specific Training Data\n",
    "Before fine-tuning, it's essential to prepare high-quality, domain-specific training data. This involves organizing your prompt-completion pairs and splitting them into training and validation sets to evaluate model performance effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794aea04-7361-4d88-8b57-b09e582b5dc5",
   "metadata": {},
   "source": [
    "### a. Organize Prompt-Completion Data\n",
    "- Assuming you've already generated output.jsonl containing your prompt-completion pairs, ensure the data is correctly formatted for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30c6e7ea-0eb3-4a54-b247-1911f1425d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages\n",
       "0  [{'role': 'system', 'content': 'You are a help...\n",
       "1  [{'role': 'system', 'content': 'You are a help...\n",
       "2  [{'role': 'system', 'content': 'You are a help...\n",
       "3  [{'role': 'system', 'content': 'You are a help...\n",
       "4  [{'role': 'system', 'content': 'You are a help..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Load the JSONL file\n",
    "jsonl_file = \"output.jsonl\"\n",
    "with open(jsonl_file, \"r\") as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few entries\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c30d7d-a4bb-4ec0-b582-f9e29fd84242",
   "metadata": {},
   "source": [
    "### b. Split Data into Training and Validation Sets\n",
    "- It's crucial to have separate datasets for training and validation to monitor the model's performance and prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0679a27d-4146-4899-8dff-a95c9eb1dbc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data saved to train.jsonl\n",
      "Validation data saved to validation.jsonl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming `df` is already defined\n",
    "# Define the split ratio\n",
    "train_ratio = 0.8  # 80% for training, 20% for validation\n",
    "\n",
    "# Perform the split\n",
    "train_df, val_df = train_test_split(df, train_size=train_ratio, random_state=42)\n",
    "\n",
    "# Save the split data into separate JSONL files\n",
    "train_file = \"train.jsonl\"\n",
    "val_file = \"validation.jsonl\"\n",
    "\n",
    "def save_to_jsonl(data, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for _, row in data.iterrows():\n",
    "            json.dump(row.to_dict(), f)  # Convert the Series to a dictionary\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "save_to_jsonl(train_df, train_file)\n",
    "save_to_jsonl(val_df, val_file)\n",
    "\n",
    "print(f\"Training data saved to {train_file}\")\n",
    "print(f\"Validation data saved to {val_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f77566-5c44-4217-92e4-00e0b5d0bffa",
   "metadata": {},
   "source": [
    "### c. Verify the Data Split \n",
    "- Ensure that both training and validation files are correctly created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dcd43c78-fcdd-465e-96ba-6c2e8ec4985c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 260\n",
      "Number of validation samples: 65\n"
     ]
    }
   ],
   "source": [
    "# Check the number of entries\n",
    "print(f\"Number of training samples: {len(train_df)}\")\n",
    "print(f\"Number of validation samples: {len(val_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cc30f2-d12f-4729-b59e-8f7ecc44ab6e",
   "metadata": {},
   "source": [
    "## 2. Fine-Tune a Base Language Model (LLM) for Your Specific Use Case\n",
    "Fine-tuning a base LLM involves training it on your domain-specific data to adapt its responses to your specific needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193dff37-f1b6-4199-b5be-1318eafa9578",
   "metadata": {},
   "source": [
    "### a. Set Up OpenAI API for Fine-Tuning\n",
    "- Ensure your OpenAI API key is set correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac12a7ba-7c41-49e8-933b-24f09fd04100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# Set your OpenAI API key as an environment variable for security\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c54b3817-152a-4c5f-a099-1f111dae995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load variables from .env file into environment\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the variables\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f341ad6c-a51b-4b68-bc87-1f4fd399851f",
   "metadata": {},
   "source": [
    "### b. Upload Training and Validation Data to OpenAI\n",
    "- OpenAI requires the training data to be uploaded before initiating the fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "569e825c-b716-4fcf-80b3-d0d6b337ffdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded train.jsonl: ID file-S42Er76HPZSRf4ij9JLT2L\n",
      "Uploaded validation.jsonl: ID file-S1JtGdAe5X9tyFRQSdN9tC\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def upload_file(file_path, purpose):\n",
    "    \"\"\"\n",
    "    Uploads a file to OpenAI for fine-tuning.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the JSONL file.\n",
    "        purpose (str): Purpose of the file (e.g., \"fine-tune\").\n",
    "    \n",
    "    Returns:\n",
    "        str: File ID assigned by OpenAI.\n",
    "    \"\"\"\n",
    "    client = OpenAI()\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            response = client.files.create(\n",
    "                file=file,\n",
    "                purpose=purpose\n",
    "            )\n",
    "        print(f\"Uploaded {file_path}: ID {response.id}\")\n",
    "        return response.id\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Upload training and validation files\n",
    "train_file_id = upload_file(train_file, \"fine-tune\")\n",
    "val_file_id = upload_file(val_file, \"fine-tune\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603881c3-40c9-451e-ac8c-794ea5da2d8c",
   "metadata": {},
   "source": [
    "### c. Initiate the Fine-Tuning Process\n",
    "- Start fine-tuning using the uploaded training data. You can specify additional parameters such as the base model, number of epochs, and learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b69aa79b-0bfa-4d41-bd0c-81457a66b16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job created: ftjob-Q0DuBG1ly5K2d2B8hCZnQXC3\n"
     ]
    }
   ],
   "source": [
    "def fine_tune_model(training_file_id, validation_file_id, model=\"gpt-4o-mini-2024-07-18\", epochs=4):\n",
    "    \"\"\"\n",
    "    Initiates the fine-tuning process.\n",
    "    \n",
    "    Args:\n",
    "        training_file_id (str): File ID for the training data.\n",
    "        validation_file_id (str): File ID for the validation data.\n",
    "        model (str): Base model to fine-tune (e.g., \"davinci\").\n",
    "        epochs (int): Number of training epochs.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Fine-tuning job details.\n",
    "    \"\"\"\n",
    "    client = OpenAI()\n",
    "    try:\n",
    "        response = client.fine_tuning.jobs.create(\n",
    "            training_file=training_file_id,\n",
    "            validation_file=validation_file_id,\n",
    "            model=model,\n",
    "            hyperparameters={\n",
    "                \"n_epochs\": epochs\n",
    "            }\n",
    "        )\n",
    "        print(f\"Fine-tuning job created: {response.id}\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error initiating fine-tuning: {e}\")\n",
    "        return None\n",
    "\n",
    "# Start fine-tuning\n",
    "fine_tune_response = fine_tune_model(train_file_id, val_file_id)\n",
    "fine_tune_job_id = fine_tune_response.id if fine_tune_response else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c94429-1ea7-4b58-9280-6f93039bd6ad",
   "metadata": {},
   "source": [
    "### d. Monitor the Fine-Tuning Job\n",
    "- Fine-tuning can take some time. Monitor the job's status to know when it's complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eae53257-3bca-43d1-bda4-4ebfed5483f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job status: validating_files\n",
      "Fine-tuning job status: validating_files\n",
      "Fine-tuning job status: queued\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: running\n",
      "Fine-tuning job status: succeeded\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "def get_fine_tune_status(job_id):\n",
    "    \"\"\"\n",
    "    Retrieves the status and details of a fine-tuning job.\n",
    "    \n",
    "    Args:\n",
    "        job_id (str): The fine-tuning job ID.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Job status details.\n",
    "    \"\"\"\n",
    "    client = OpenAI()\n",
    "    try:\n",
    "        response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving job status: {e}\")\n",
    "        return None\n",
    "\n",
    "# Polling the job status\n",
    "if fine_tune_job_id:\n",
    "    while True:\n",
    "        status_response = get_fine_tune_status(fine_tune_job_id)\n",
    "        if status_response:\n",
    "            status = status_response.status\n",
    "            print(f\"Fine-tuning job status: {status}\")\n",
    "            \n",
    "            # Print out more detailed error information if the job failed\n",
    "            if status == \"failed\":\n",
    "                print(\"\\nDetailed Error Information:\")\n",
    "                print(f\"Error Message: {status_response.error}\")\n",
    "                \n",
    "                # Additional error details if available\n",
    "                if hasattr(status_response, 'validation_file'):\n",
    "                    print(f\"Validation File: {status_response.validation_file}\")\n",
    "                \n",
    "                break\n",
    "            \n",
    "            if status in [\"succeeded\", \"failed\"]:\n",
    "                break\n",
    "        else:\n",
    "            print(\"Failed to retrieve job status.\")\n",
    "            break\n",
    "        time.sleep(60)  # Wait for 1 minute before checking again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f38d17-f5fd-46e0-94de-e077980d008e",
   "metadata": {},
   "source": [
    "### e. Retrieve the Fine-Tuned Model\n",
    "- Once the fine-tuning job is complete, retrieve the fine-tuned model's name for usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3e62e90-6252-4484-a28a-47f96d8505ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model available: ft:gpt-4o-mini-2024-07-18:personal::Ae9mdwfc\n"
     ]
    }
   ],
   "source": [
    "if status_response and status_response.status == \"succeeded\":\n",
    "    if hasattr(status_response, 'fine_tuned_model'):\n",
    "        fine_tuned_model = status_response.fine_tuned_model\n",
    "        print(f\"Fine-tuned model available: {fine_tuned_model}\")\n",
    "    else:\n",
    "        print(\"Fine-tuned model information not available.\")\n",
    "else:\n",
    "    print(\"Fine-tuning was not successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdc030d-3c0e-45cb-aee7-dec7831e2bba",
   "metadata": {},
   "source": [
    "## 3. Implement Evaluation Metrics for Model Performance\n",
    "After fine-tuning, it's vital to evaluate the model's performance using various metrics to ensure it meets your requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7269c614-3c22-468c-ae62-b0fc2d7314a5",
   "metadata": {},
   "source": [
    "### a. Define Evaluation Metrics\n",
    "Common evaluation metrics for language models include:\n",
    "\n",
    "- **Perplexity**: Measures how well the model predicts a sample.\n",
    "- **Accuracy**: Percentage of correct responses.\n",
    "- **BLEU Score**: Evaluates the similarity between generated text and reference text.\n",
    "- **ROUGE Score**: Measures the overlap of n-grams between generated and reference texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0b4bd8c3-54d1-4ac0-95cf-e101c71f03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import nltk\n",
    "\n",
    "# More robust NLTK resource download\n",
    "def download_nltk_resources():\n",
    "    try:\n",
    "        # Attempt to download multiple resources\n",
    "        resources = ['punkt', 'punkt_tab']\n",
    "        for resource in resources:\n",
    "            try:\n",
    "                nltk.download(resource, quiet=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not download {resource}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in NLTK resource download: {e}\")\n",
    "\n",
    "# Call this at the start of your script\n",
    "download_nltk_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1977d19-b727-4bce-a1a0-6833a4ad26e5",
   "metadata": {},
   "source": [
    "### b. Prepare Validation Data for Evaluation\n",
    "Use the validation set to generate model responses and compare them with the reference completions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84a3c08-035b-4be0-8ad3-693f8db2bf6f",
   "metadata": {},
   "source": [
    "## Model Evaluation with OpenAI GPT and Custom Metrics\n",
    "\n",
    "### Overview\n",
    "This script evaluates the performance of a fine-tuned OpenAI GPT model on a validation dataset. It leverages metrics like **accuracy** and a custom **BLEU score** to assess the quality of generated completions compared to expected outputs. The code processes a `.jsonl` validation file, generates model predictions, and computes evaluation metrics for robust performance analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "1. **Data Loading**  \n",
    "   - Loads validation data from a `.jsonl` file into a Pandas DataFrame, ensuring error handling for file operations.\n",
    "\n",
    "2. **OpenAI Model Integration**  \n",
    "   - Interacts with the OpenAI ChatCompletion API to generate model completions based on provided prompts and system messages.\n",
    "\n",
    "3. **Custom BLEU Score Calculation**  \n",
    "   - Implements a simplified BLEU score to evaluate the similarity between generated completions and expected outputs. Includes fallback tokenization for robustness.\n",
    "\n",
    "4. **Evaluation Process**  \n",
    "   - Processes each validation sample to compute:\n",
    "     - **Accuracy**: Exact match between generated and expected completions.\n",
    "     - **Custom BLEU Score**: Measures partial matching precision and brevity penalty.\n",
    "\n",
    "5. **Error Handling**  \n",
    "   - Includes comprehensive error handling for missing data, incorrect formats, and API issues to ensure smooth evaluation.\n",
    "\n",
    "6. **Metrics Calculation**  \n",
    "   - Computes and reports average accuracy and BLEU scores across all samples.\n",
    "\n",
    "7. **Main Function**  \n",
    "   - Orchestrates the loading of data, validation checks, and evaluation process, ensuring that the required environment variables and fine-tuned model are correctly configured.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Features\n",
    "- Robust data handling for `.jsonl` format.\n",
    "- Custom BLEU score implementation with fallback tokenization.\n",
    "- Dynamic and structured prompt handling for OpenAI API.\n",
    "- Comprehensive evaluation metrics for model performance.\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "This script is designed for evaluating fine-tuned language models, providing insights into their ability to generate accurate and contextually relevant completions. It is highly customizable and supports integration with OpenAI's GPT models for various NLP tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "285ff60b-a29b-4197-9cb0-bb0dc293d678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data Loaded Successfully.\n",
      "Number of samples: 65\n",
      "OpenAI API key is set.\n",
      "Using fine-tuned model: ft:gpt-4o-mini-2024-07-18:personal::Ae9mdwfc\n",
      "\n",
      "Starting model evaluation...\n",
      "\n",
      "Total samples to evaluate: 65\n",
      "\n",
      "\n",
      "Sample 1/65:\n",
      "User Prompt: What is significant about chandipur beach in balasore?\n",
      "Expected Completion: chandipur beach in balasore is known for its recreational. it was established in unknown and has a rating of 4.2. ideal visit time: morning.\n",
      "Generated Completion: chandipur beach in balasore is a beach rated 4.5 on google. it's best visited in the morning.\n",
      "\n",
      "Sample 2/65:\n",
      "User Prompt: What makes wonderla amusement park in kochi special?\n",
      "Expected Completion: wonderla amusement park in kochi is a amusement park rated 4.6 on google. it's best visited in the all.\n",
      "Generated Completion: located in kochi, wonderla amusement park is a popular recreational destination built in 2000. it is rated 4.4 on google reviews.\n",
      "\n",
      "Sample 3/65:\n",
      "User Prompt: Where can I experience religious significance in vijayawada?\n",
      "Expected Completion: located in vijayawada, kanaka durga temple is a popular religious destination built in unknown. it is rated 4.7 on google reviews.\n",
      "Generated Completion: located in vijayawada, kanaka durga temple is a popular religious destination built in unknown. it is rated 4.7 on google reviews.\n",
      "\n",
      "Sample 4/65:\n",
      "User Prompt: Which park in delhi is worth visiting?\n",
      "Expected Completion: sunder nursery in delhi is known for its botanical. it was established in 1600 and has a rating of 4.6. ideal visit time: afternoon.\n",
      "Generated Completion: lodi garden in delhi is a park rated 4.5 on google. it's best visited in the morning.\n",
      "\n",
      "Sample 5/65:\n",
      "User Prompt: Which memorial in amritsar is worth visiting?\n",
      "Expected Completion: located in amritsar, jallianwala bagh is a popular historical destination built in 1951. it is rated 4.8 on google reviews.\n",
      "Generated Completion: jallianwala bagh memorial in amritsar is a memorial rated 4.6 on google. it's best visited in the all.\n",
      "\n",
      "Sample 6/65:\n",
      "User Prompt: What is significant about hazarduari palace in murshidabad?\n",
      "Expected Completion: hazarduari palace is a palace in murshidabad, built in 1837. it has a google review rating of 4.5 and is best visited in the morning.\n",
      "Generated Completion: hazarduari palace in murshidabad is a palace rated 4.5 on google. it's best visited in the afternoon.\n",
      "\n",
      "Sample 7/65:\n",
      "User Prompt: Suggest a recreational destination in puducherry.\n",
      "Expected Completion: promenade beach in puducherry is known for its recreational. it was established in unknown and has a rating of 4.5. ideal visit time: morning.\n",
      "Generated Completion: for recreational experiences in puducherry, promenade beach is a top choice. built in unknown, it has a google review rating of 4.6.\n",
      "\n",
      "Sample 8/65:\n",
      "User Prompt: Where can I experience religious significance in jammu?\n",
      "Expected Completion: vaishno devi in jammu is a temple rated 4.7 on google. it's best visited in the all.\n",
      "Generated Completion: located in jammu, vaishno devi temple is a popular religious destination built in unknown. it is rated 4.8 on google reviews.\n",
      "\n",
      "Sample 9/65:\n",
      "User Prompt: Tell me about kargil war memorial in kargil.\n",
      "Expected Completion: kargil war memorial in kargil is known for its historical. it was established in 24 and has a rating of 4.8. ideal visit time: all.\n",
      "Generated Completion: kargil war memorial in kargil is a memorial rated 4.7 on google. it's best visited in the all.\n",
      "\n",
      "Sample 10/65:\n",
      "User Prompt: Where can I experience wildlife significance in wayanad?\n",
      "Expected Completion: wayanad wildlife sanctuary in wayanad is known for its wildlife. it was established in unknown and has a rating of 4.5. ideal visit time: all.\n",
      "Generated Completion: located in wayanad, wayanad wildlife sanctuary is a popular wildlife destination built in 1973. it is rated 4.2 on google reviews.\n",
      "\n",
      "Processed 10 samples out of 65.\n",
      "\n",
      "\n",
      "Sample 11/65:\n",
      "User Prompt: Where can I experience historical significance in agra?\n",
      "Expected Completion: taj mahal in agra is known for its historical. it was established in 1632 and has a rating of 4.6. ideal visit time: morning.\n",
      "Generated Completion: agra fort in agra is a fort rated 4.5 on google. it's best visited in the afternoon.\n",
      "\n",
      "Sample 12/65:\n",
      "User Prompt: Tell me about uppalapadu bird sanctuary in guntur.\n",
      "Expected Completion: for wildlife experiences in guntur, uppalapadu bird sanctuary is a top choice. built in unknown, it has a google review rating of 4.4.\n",
      "Generated Completion: for wildlife experiences in guntur, uppalapadu bird sanctuary is a top choice. built in unknown, it has a google review rating of 4.2.\n",
      "\n",
      "Sample 13/65:\n",
      "User Prompt: Where can I experience shopping significance in kochi?\n",
      "Expected Completion: lulu international shopping mall in kochi is a mall rated 4.6 on google. it's best visited in the all.\n",
      "Generated Completion: located in kochi, lulu mall is a popular shopping destination built in 2013. it is rated 4.5 on google reviews.\n",
      "\n",
      "Sample 14/65:\n",
      "User Prompt: Which fort in gwalior is worth visiting?\n",
      "Expected Completion: gwalior fort in gwalior is a fort rated 4.5 on google. it's best visited in the morning.\n",
      "Generated Completion: located in gwalior, gwalior fort is a popular historical destination built in 1253. it is rated 4.6 on google reviews.\n",
      "\n",
      "Sample 15/65:\n",
      "User Prompt: Suggest a religious destination in gujarat.\n",
      "Expected Completion: located in gandhinagar, akshardham is a popular religious destination built in 1992. it is rated 4.6 on google reviews.\n",
      "Generated Completion: akshardham temple is a temple in gandhinagar, built in 2014. it has a google review rating of 4.8 and is best visited in the afternoon.\n",
      "\n",
      "Sample 16/65:\n",
      "User Prompt: Which lake in dalhousie is worth visiting?\n",
      "Expected Completion: khajjiar lake in dalhousie is a lake rated 4.5 on google. it's best visited in the morning.\n",
      "Generated Completion: located in dalhousie, dal lake is a popular nature destination built in unknown. it is rated 4.4 on google reviews.\n",
      "\n",
      "Sample 17/65:\n",
      "User Prompt: Where can I experience historical significance in mandu?\n",
      "Expected Completion: located in mandu, jahaz mahal is a popular historical destination built in 1500. it is rated 3.9 on google reviews.\n",
      "Generated Completion: located in mandu, jahaz mahal is a popular historical destination built in 1500. it is rated 4.5 on google reviews.\n",
      "\n",
      "Sample 18/65:\n",
      "User Prompt: Which national park in bandhavgarh is worth visiting?\n",
      "Expected Completion: bandhavgarh national park is a national park in bandhavgarh, built in 1968. it has a google review rating of 4.5 and is best visited in the morning.\n",
      "Generated Completion: bandhavgarh national park in bandhavgarh is known for its wildlife. it was established in 1968 and has a rating of 4.4. ideal visit time: morning.\n",
      "\n",
      "Sample 19/65:\n",
      "User Prompt: What is significant about elephanta caves in mumbai?\n",
      "Expected Completion: elephanta caves is a monument in mumbai, built in 1987. it has a google review rating of 4.3 and is best visited in the all.\n",
      "Generated Completion: elephanta caves in mumbai is a cave rated 4.4 on google. it's best visited in the afternoon.\n",
      "\n",
      "Sample 20/65:\n",
      "User Prompt: Tell me about chandni chowk in delhi.\n",
      "Expected Completion: located in delhi, chandni chowk is a popular market destination built in 1700. it is rated 4.2 on google reviews.\n",
      "Generated Completion: for market experiences in delhi, chandni chowk is a top choice. built in 1650, it has a google review rating of 4.4.\n",
      "\n",
      "Processed 20 samples out of 65.\n",
      "\n",
      "\n",
      "Sample 21/65:\n",
      "User Prompt: Suggest a wildlife destination in rajasthan.\n",
      "Expected Completion: located in sawai madhopur, ranthambore national park is a popular wildlife destination built in 1980. it is rated 4.6 on google reviews.\n",
      "Generated Completion: ranthambore national park in sawai madhopur is a national park rated 4.5 on google. it's best visited in the morning.\n",
      "\n",
      "Sample 22/65:\n",
      "User Prompt: Suggest a religious destination in uttarakhand.\n",
      "Expected Completion: for religious experiences in chopta, tungnath temple is a top choice. built in 751, it has a google review rating of 4.8.\n",
      "Generated Completion: tungnath temple in chopta is a temple rated 4.8 on google. it's best visited in the all.\n",
      "\n",
      "Sample 23/65:\n",
      "User Prompt: What makes kalighat kali temple in kolkata special?\n",
      "Expected Completion: kalighat kali temple in kolkata is known for its religious. it was established in 1809 and has a rating of 4.4. ideal visit time: morning.\n",
      "Generated Completion: located in kolkata, kalighat kali temple is a popular religious destination built in 1809. it is rated 4.6 on google reviews.\n",
      "\n",
      "Sample 24/65:\n",
      "User Prompt: What is significant about pobitora wildlife sanctuary in guwahati?\n",
      "Expected Completion: pobitora wildlife sanctuary in guwahati is known for its wildlife. it was established in 1987 and has a rating of 4.4. ideal visit time: all.\n",
      "Generated Completion: for wildlife experiences in guwahati, pobitora wildlife sanctuary is a top choice. built in 1987, it has a google review rating of 4.4.\n",
      "\n",
      "Sample 25/65:\n",
      "User Prompt: What is significant about wagah border in amritsar?\n",
      "Expected Completion: wagah border is a border crossing in amritsar, built in 1950. it has a google review rating of 4.8 and is best visited in the evening.\n",
      "Generated Completion: wagah border in amritsar is a border rated 4.6 on google. it's best visited in the evening.\n",
      "\n",
      "Sample 26/65:\n",
      "User Prompt: Which amusement park in bengaluru is worth visiting?\n",
      "Expected Completion: for entertainment experiences in bengaluru, wonderla amusement park is a top choice. built in 2005, it has a google review rating of 4.5.\n",
      "Generated Completion: located in bengaluru, fun world is a popular amusement park rated 3.9 on google. it's best visited in the all.\n",
      "\n",
      "Sample 27/65:\n",
      "User Prompt: Suggest a nature destination in karnataka.\n",
      "Expected Completion: located in gokarna, om beach is a popular nature destination built in unknown. it is rated 4.5 on google reviews.\n",
      "Generated Completion: for nature experiences in gokarna, om beach is a top choice. built in unknown, it has a google review rating of 4.6.\n",
      "\n",
      "Sample 28/65:\n",
      "User Prompt: Which beach in mangalore is worth visiting?\n",
      "Expected Completion: located in mangalore, panambur beach is a popular recreational destination built in unknown. it is rated 4.5 on google reviews.\n",
      "Generated Completion: located in mangalore, panambur beach is a popular scenic destination built in unknown. it is rated 4.4 on google reviews.\n",
      "\n",
      "Sample 29/65:\n",
      "User Prompt: Suggest a scenic destination in goa.\n",
      "Expected Completion: miramar beach in goa is known for its scenic. it was established in unknown and has a rating of 4.2. ideal visit time: evening.\n",
      "Generated Completion: aguada beach in goa is a beach rated 4.5 on google. it's best visited in the evening.\n",
      "\n",
      "Sample 30/65:\n",
      "User Prompt: Where can I experience religious significance in gangtok?\n",
      "Expected Completion: located in gangtok, baba harbhajan singh temple is a popular religious destination built in 1967. it is rated 4.7 on google reviews.\n",
      "Generated Completion: rumtek monastery in gangtok is a monastery rated 4.6 on google. it's best visited in the all.\n",
      "\n",
      "Processed 30 samples out of 65.\n",
      "\n",
      "\n",
      "Sample 31/65:\n",
      "User Prompt: What makes kodaikanal lake in kodaikanal special?\n",
      "Expected Completion: kodaikanal lake in kodaikanal is a lake rated 3.9 on google. it's best visited in the morning.\n",
      "Generated Completion: located in kodaikanal, kodaikanal lake is a popular nature destination built in 1801. it is rated 4.2 on google reviews.\n",
      "\n",
      "Sample 32/65:\n",
      "User Prompt: Tell me about magnetic hill in leh.\n",
      "Expected Completion: for nature experiences in leh, magnetic hill is a top choice. built in unknown, it has a google review rating of 3.7.\n",
      "Generated Completion: magnetic hill in leh is a hill rated 4.4 on google. it's best visited in the morning.\n",
      "\n",
      "Sample 33/65:\n",
      "User Prompt: Where can I experience shopping significance in gurugram?\n",
      "Expected Completion: ambience mall in gurugram is a mall rated 4.6 on google. it's best visited in the afternoon.\n",
      "Generated Completion: located in gurugram, dlf cyberhub is a popular shopping destination built in 2013. it is rated 4.6 on google reviews.\n",
      "\n",
      "Sample 34/65:\n",
      "User Prompt: Tell me about jim corbett national park in jim corbett.\n",
      "Expected Completion: jim corbett national park in jim corbett is known for its wildlife. it was established in 1936 and has a rating of 4.4. ideal visit time: all.\n",
      "Generated Completion: located in jim corbett, jim corbett national park is a popular wildlife destination built in 1936. it is rated 4.4 on google reviews.\n",
      "\n",
      "Sample 35/65:\n",
      "User Prompt: Tell me about budhha smriti park in patna.\n",
      "Expected Completion: budhha smriti park is a park in patna, built in unknown. it has a google review rating of 4.4 and is best visited in the all.\n",
      "Generated Completion: budhha smriti park in patna is a park rated 4.4 on google. it's best visited in the all.\n",
      "\n",
      "Sample 36/65:\n",
      "User Prompt: Tell me about binsar wildlife sanctuary in almora.\n",
      "Expected Completion: binsar wildlife sanctuary in almora is a wildlife sanctuary rated 4.3 on google. it's best visited in the all.\n",
      "Generated Completion: binsar wildlife sanctuary in almora is a wildlife sanctuary rated 4.4 on google. it's best visited in the morning.\n",
      "\n",
      "Sample 37/65:\n",
      "User Prompt: What makes dudhsagar falls in goa special?\n",
      "Expected Completion: dudhsagar falls in goa is a waterfall rated 4.6 on google. it's best visited in the afternoon.\n",
      "Generated Completion: dudhsagar falls in goa is a waterfall rated 4.5 on google. it's best visited in the morning.\n",
      "\n",
      "Sample 38/65:\n",
      "User Prompt: What makes golconda fort in hyderabad special?\n",
      "Expected Completion: located in hyderabad, golconda fort is a popular historical destination built in 1600. it is rated 4.4 on google reviews.\n",
      "Generated Completion: located in hyderabad, golconda fort is a popular historical destination built in 1143. it is rated 4.4 on google reviews.\n",
      "\n",
      "Sample 39/65:\n",
      "User Prompt: What makes manikaran sahib in manikaran special?\n",
      "Expected Completion: manikaran sahib in manikaran is a gurudwara rated 4.6 on google. it's best visited in the morning.\n",
      "Generated Completion: located in manikaran, manikaran sahib is a popular religious destination built in unknown. it is rated 4.7 on google reviews.\n",
      "\n",
      "Sample 40/65:\n",
      "User Prompt: Which ski resort in kufri is worth visiting?\n",
      "Expected Completion: for recreational experiences in kufri, kufri fun world is a top choice. built in 1975, it has a google review rating of 3.8.\n",
      "Generated Completion: kufri ski resort in kufri is a ski resort rated 4.4 on google. it's best visited in the winter.\n",
      "\n",
      "Processed 40 samples out of 65.\n",
      "\n",
      "\n",
      "Sample 41/65:\n",
      "User Prompt: Tell me about ooty lake in ooty.\n",
      "Expected Completion: ooty lake in ooty is a lake rated 4.1 on google. it's best visited in the morning.\n",
      "Generated Completion: located in ooty, ooty lake is a popular nature destination built in 1842. it is rated 3.9 on google reviews.\n",
      "\n",
      "Sample 42/65:\n",
      "User Prompt: Tell me about victoria memorial in kolkata.\n",
      "Expected Completion: victoria memorial in kolkata is a museum rated 4.6 on google. it's best visited in the morning.\n",
      "Generated Completion: victoria memorial is a museum in kolkata, built in 1921. it has a google review rating of 4.6 and is best visited in the afternoon.\n",
      "\n",
      "Sample 43/65:\n",
      "User Prompt: Which temple in murudeshwar is worth visiting?\n",
      "Expected Completion: murudeshwar temple in murudeshwar is a temple rated 4.7 on google. it's best visited in the all.\n",
      "Generated Completion: murudeshwar temple in murudeshwar is a temple rated 4.7 on google. it's best visited in the all.\n",
      "\n",
      "Sample 44/65:\n",
      "User Prompt: What makes auli ski resort in auli special?\n",
      "Expected Completion: located in auli, auli ski resort is a popular adventure destination built in 1990. it is rated 4.5 on google reviews.\n",
      "Generated Completion: auli ski resort in auli is known for its sports. it was established in unknown and has a rating of 4.5. ideal visit time: all.\n",
      "\n",
      "Sample 45/65:\n",
      "User Prompt: Suggest a religious destination in west bengal.\n",
      "Expected Completion: dakshineswar kali temple in kolkata is a temple rated 4.7 on google. it's best visited in the morning.\n",
      "Generated Completion: belur math is a monastery in kolkata, built in 1938. it has a google review rating of 4.7 and is best visited in the afternoon.\n",
      "\n",
      "Sample 46/65:\n",
      "User Prompt: Which commercial complex in gurugram is worth visiting?\n",
      "Expected Completion: dlf cyberhub is a commercial complex in gurugram, built in unknown. it has a google review rating of 4.7 and is best visited in the afternoon.\n",
      "Generated Completion: located in gurugram, cyber hub is a popular commercial complex rated 4.6 on google. it's best visited in the all.\n",
      "\n",
      "Sample 47/65:\n",
      "User Prompt: Where can I experience religious significance in ajmer?\n",
      "Expected Completion: ajmer sharif dargah in ajmer is a shrine rated 4.6 on google. it's best visited in the all.\n",
      "Generated Completion: located in ajmer, dargah sharif is a popular religious destination built in 1192. it is rated 4.7 on google reviews.\n",
      "\n",
      "Sample 48/65:\n",
      "User Prompt: Which zoo in bhubaneswar is worth visiting?\n",
      "Expected Completion: for wildlife experiences in bhubaneswar, nandankanan zoological park is a top choice. built in 1960, it has a google review rating of 4.4.\n",
      "Generated Completion: nandankanan zoological park in bhubaneswar is a zoo rated 4.5 on google. it's best visited in the afternoon.\n",
      "\n",
      "Sample 49/65:\n",
      "User Prompt: What is significant about chapora fort in goa?\n",
      "Expected Completion: for historical experiences in goa, chapora fort is a top choice. built in 1617, it has a google review rating of 4.2.\n",
      "Generated Completion: chapora fort in goa is a fort rated 4.4 on google. it's best visited in the afternoon.\n",
      "\n",
      "Sample 50/65:\n",
      "User Prompt: Tell me about marine drive in mumbai.\n",
      "Expected Completion: located in mumbai, marine drive is a popular scenic destination built in unknown. it is rated 4.5 on google reviews.\n",
      "Generated Completion: marine drive in mumbai is known for its scenic. it was established in 1920 and has a rating of 4.6. ideal visit time: evening.\n",
      "\n",
      "Processed 50 samples out of 65.\n",
      "\n",
      "\n",
      "Sample 51/65:\n",
      "User Prompt: Suggest a recreational destination in gujarat.\n",
      "Expected Completion: kankaria lake in ahmedabad is a lake rated 4.5 on google. it's best visited in the afternoon.\n",
      "Generated Completion: located in ahmedabad, sabarmati riverfront is a popular recreational destination built in 2012. it is rated 4.6 on google reviews.\n",
      "\n",
      "Sample 52/65:\n",
      "User Prompt: Which fort in jaipur is worth visiting?\n",
      "Expected Completion: for historical experiences in jaipur, jaigarh fort is a top choice. built in 1726, it has a google review rating of 4.5.\n",
      "Generated Completion: amber fort in jaipur is a fort rated 4.6 on google. it's best visited in the morning.\n",
      "\n",
      "Sample 53/65:\n",
      "User Prompt: Which fort in delhi is worth visiting?\n",
      "Expected Completion: located in delhi, red fort is a popular historical destination built in 1648. it is rated 4.5 on google reviews.\n",
      "Generated Completion: agrasen ki baoli in delhi is a stepwell rated 4.2 on google. it's best visited in the afternoon.\n",
      "\n",
      "Sample 54/65:\n",
      "User Prompt: Where can I experience food significance in ahmedabad?\n",
      "Expected Completion: manek chowk in ahmedabad is known for its food. it was established in unknown and has a rating of 4.4. ideal visit time: night.\n",
      "Generated Completion: located in ahmedabad, manek chowk is a popular food destination built in unknown. it is rated 4.4 on google reviews.\n",
      "\n",
      "Sample 55/65:\n",
      "User Prompt: What is significant about science city in ahmedabad?\n",
      "Expected Completion: science city is a science in ahmedabad, built in 2002. it has a google review rating of 4.4 and is best visited in the all.\n",
      "Generated Completion: science city in ahmedabad is a science museum rated 4.4 on google. it's best visited in the morning.\n",
      "\n",
      "Sample 56/65:\n",
      "User Prompt: Where can I experience recreational significance in puducherry?\n",
      "Expected Completion: for recreational experiences in puducherry, paradise beach is a top choice. built in unknown, it has a google review rating of 4.5.\n",
      "Generated Completion: for recreational experiences in puducherry, pondicherry beach is a top choice. built in unknown, it has a google review rating of 4.6.\n",
      "\n",
      "Sample 57/65:\n",
      "User Prompt: Suggest a nature destination in chhattisgarh.\n",
      "Expected Completion: for nature experiences in bastar, chitrakote falls is a top choice. built in unknown, it has a google review rating of 4.6.\n",
      "Generated Completion: kanger valley national park in bastar is known for its wildlife. it was established in 1982 and has a rating of 4.4. ideal visit time: all.\n",
      "\n",
      "Sample 58/65:\n",
      "User Prompt: What is significant about chaubatia gardens in ranikhet?\n",
      "Expected Completion: chaubatia gardens is a orchard in ranikhet, built in 1868. it has a google review rating of 4.0 and is best visited in the all.\n",
      "Generated Completion: located in ranikhet, chaubatia gardens is a popular botanical destination built in 1952. it is rated 4.4 on google reviews.\n",
      "\n",
      "Sample 59/65:\n",
      "User Prompt: What makes waste to wonder park in delhi special?\n",
      "Expected Completion: for environmental experiences in delhi, waste to wonder park is a top choice. built in 2019, it has a google review rating of 4.1.\n",
      "Generated Completion: waste to wonder park in delhi is a park rated 4.4 on google. it's best visited in the afternoon.\n",
      "\n",
      "Sample 60/65:\n",
      "User Prompt: Tell me about statue of unity in kevadia.\n",
      "Expected Completion: statue of unity in kevadia is a monument rated 4.6 on google. it's best visited in the all.\n",
      "Generated Completion: for cultural experiences in kevadia, statue of unity is a top choice. built in 2018, it has a google review rating of 4.6.\n",
      "\n",
      "Processed 60 samples out of 65.\n",
      "\n",
      "\n",
      "Sample 61/65:\n",
      "User Prompt: Suggest a cultural destination in madhya pradesh.\n",
      "Expected Completion: located in bhopal, madhya pradesh tribal museum is a popular cultural destination built in 2013. it is rated 4.7 on google reviews.\n",
      "Generated Completion: sanchi stupa is a monument in bhopal, built in -300. it has a google review rating of 4.7 and is best visited in the afternoon.\n",
      "\n",
      "Sample 62/65:\n",
      "User Prompt: What is significant about tara tarini temple in berhampur?\n",
      "Expected Completion: located in berhampur, tara tarini temple is a popular religious destination built in ancient. it is rated 4.6 on google reviews.\n",
      "Generated Completion: tara tarini temple in berhampur is a temple rated 4.7 on google. it's best visited in the all.\n",
      "\n",
      "Sample 63/65:\n",
      "User Prompt: What makes arambol beach in goa special?\n",
      "Expected Completion: located in goa, arambol beach is a popular scenic destination built in unknown. it is rated 4.6 on google reviews.\n",
      "Generated Completion: arambol beach in goa is a beach rated 4.5 on google. it's best visited in the evening.\n",
      "\n",
      "Sample 64/65:\n",
      "User Prompt: What makes ajanta caves in aurangabad special?\n",
      "Expected Completion: ajanta caves in aurangabad is known for its historical. it was established in 200 and has a rating of 4.6. ideal visit time: afternoon.\n",
      "Generated Completion: for historical experiences in aurangabad, ajanta caves is a top choice. built in -200, it has a google review rating of 4.6.\n",
      "\n",
      "Sample 65/65:\n",
      "User Prompt: Suggest a architectural destination in west bengal.\n",
      "Expected Completion: for architectural experiences in hooghly, hangseswari temple is a top choice. built in 1814, it has a google review rating of 4.6.\n",
      "Generated Completion: located in hooghly, bandel church is a popular architectural destination built in 1661. it is rated 4.6 on google reviews.\n",
      "\n",
      "Evaluation Metrics:\n",
      "Average Accuracy: 0.03\n",
      "Average BLEU Score: 0.58\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Ensure NLTK resources are downloaded\n",
    "try:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading NLTK resources: {e}\")\n",
    "\n",
    "# Function to load validation data from a .jsonl file\n",
    "def load_validation_data(file_path):\n",
    "    try:\n",
    "        data = []\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                data.append(json.loads(line))\n",
    "        return pd.DataFrame(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading validation data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Function to generate model completion using ChatCompletion API\n",
    "def generate_completion(messages, model, max_tokens=100):\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=0.7,\n",
    "            n=1,\n",
    "            stop=None\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating completion: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Custom BLEU score calculation function\n",
    "def calculate_custom_bleu(reference, candidate):\n",
    "    \"\"\"\n",
    "    Calculate a simplified BLEU-like score with fallback tokenization\n",
    "    \"\"\"\n",
    "    # Fallback tokenization method if NLTK fails\n",
    "    def simple_tokenize(text):\n",
    "        return text.lower().split()\n",
    "    \n",
    "    try:\n",
    "        # First try NLTK tokenization\n",
    "        try:\n",
    "            ref_tokens = word_tokenize(reference.lower())\n",
    "            cand_tokens = word_tokenize(candidate.lower())\n",
    "        except Exception:\n",
    "            # Fallback to simple tokenization if NLTK fails\n",
    "            ref_tokens = simple_tokenize(reference)\n",
    "            cand_tokens = simple_tokenize(candidate)\n",
    "        \n",
    "        # If either is empty, return 0\n",
    "        if not ref_tokens or not cand_tokens:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate modified precision\n",
    "        matches = sum(1 for token in cand_tokens if token in ref_tokens)\n",
    "        precision = matches / len(cand_tokens)\n",
    "        \n",
    "        # Add brevity penalty\n",
    "        brevity_penalty = min(1, len(cand_tokens) / len(ref_tokens)) if len(ref_tokens) > 0 else 0\n",
    "        \n",
    "        # Combine precision and brevity penalty\n",
    "        bleu_score = precision * brevity_penalty\n",
    "        \n",
    "        return bleu_score\n",
    "    except Exception as e:\n",
    "        print(f\"BLEU score calculation error: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "# Function to compute evaluation metrics with enhanced error handling\n",
    "def evaluate_model(model, validation_data):\n",
    "    print(\"\\nStarting model evaluation...\\n\")\n",
    "    \n",
    "    # Validate input data\n",
    "    if validation_data.empty:\n",
    "        print(\"Error: Validation data is empty.\")\n",
    "        return {\"average_accuracy\": 0, \"average_bleu_score\": 0}\n",
    "    \n",
    "    # Ensure the 'messages' column exists\n",
    "    if 'messages' not in validation_data.columns:\n",
    "        raise ValueError(f\"Expected 'messages' column in validation data. Found columns: {validation_data.columns}\")\n",
    "    \n",
    "    accuracies = []\n",
    "    bleu_scores = []\n",
    "    \n",
    "    total_samples = len(validation_data)\n",
    "    print(f\"Total samples to evaluate: {total_samples}\\n\")\n",
    "    \n",
    "    for index, row in validation_data.iterrows():\n",
    "        messages = row['messages']\n",
    "        \n",
    "        if not isinstance(messages, list):\n",
    "            print(f\"Row {index} has invalid 'messages' format. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Extract the user prompt and the expected assistant completion\n",
    "        user_prompt = \"\"\n",
    "        expected_completion = \"\"\n",
    "        system_prompt = \"\"\n",
    "        \n",
    "        for message in messages:\n",
    "            if message['role'] == 'system':\n",
    "                system_prompt = message['content']\n",
    "            elif message['role'] == 'user':\n",
    "                user_prompt += message['content'] + \"\\n\"\n",
    "            elif message['role'] == 'assistant':\n",
    "                expected_completion += message['content'] + \"\\n\"\n",
    "        \n",
    "        user_prompt = user_prompt.strip()\n",
    "        expected_completion = expected_completion.strip().lower()\n",
    "        \n",
    "        if not user_prompt or not expected_completion:\n",
    "            print(f\"Row {index} is missing user prompt or expected completion. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Prepare messages for the model\n",
    "        input_messages = []\n",
    "        if system_prompt:\n",
    "            input_messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        input_messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "        \n",
    "        # Generate completion\n",
    "        generated = generate_completion(input_messages, model).lower().strip()\n",
    "        \n",
    "        # Debug: Print the generated and expected completions\n",
    "        print(f\"\\nSample {index + 1}/{total_samples}:\")\n",
    "        print(f\"User Prompt: {user_prompt}\")\n",
    "        print(f\"Expected Completion: {expected_completion}\")\n",
    "        print(f\"Generated Completion: {generated}\")\n",
    "        \n",
    "        # Compute Accuracy (exact match)\n",
    "        accuracy = int(generated == expected_completion)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        # Compute Custom BLEU Score\n",
    "        try:\n",
    "            bleu_score = calculate_custom_bleu(expected_completion, generated)\n",
    "            bleu_scores.append(bleu_score)\n",
    "        except Exception as bleu_error:\n",
    "            print(f\"BLEU score calculation error for sample {index}: {bleu_error}\")\n",
    "            bleu_scores.append(0)\n",
    "        \n",
    "        # Optional: Print progress every 10 samples\n",
    "        if (index + 1) % 10 == 0:\n",
    "            print(f\"\\nProcessed {index + 1} samples out of {total_samples}.\\n\")\n",
    "    \n",
    "    # Calculate average metrics with error handling\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies) if accuracies else 0\n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n",
    "    \n",
    "    return {\n",
    "        \"average_accuracy\": avg_accuracy,\n",
    "        \"average_bleu_score\": avg_bleu\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # Load validation data\n",
    "    val_df = load_validation_data('validation.jsonl')  # Replace with your actual file path\n",
    "    \n",
    "    if val_df.empty:\n",
    "        print(\"Failed to load validation data. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Validation Data Loaded Successfully.\")\n",
    "    print(f\"Number of samples: {len(val_df)}\")\n",
    "    \n",
    "    # Set OpenAI API key\n",
    "    openai.api_key = os.getenv('OPENAI_API_KEY')  # Ensure this environment variable is set\n",
    "    \n",
    "    if openai.api_key is None:\n",
    "        raise ValueError(\"OpenAI API key is not set. Please set it as an environment variable 'OPENAI_API_KEY'.\")\n",
    "    else:\n",
    "        print(\"OpenAI API key is set.\")\n",
    "    \n",
    "    # Define fine-tuned model\n",
    "    fine_tuned_model = \"ft:gpt-4o-mini-2024-07-18:personal::Ae9mdwfc\"  # Replace with your actual fine-tuned model name\n",
    "    \n",
    "    if not fine_tuned_model:\n",
    "        raise ValueError(\"Fine-tuned model name is not specified.\")\n",
    "    else:\n",
    "        print(f\"Using fine-tuned model: {fine_tuned_model}\")\n",
    "    \n",
    "    try:\n",
    "        # Perform evaluation\n",
    "        evaluation_metrics = evaluate_model(fine_tuned_model, val_df)\n",
    "        \n",
    "        # Print Evaluation Metrics\n",
    "        print(\"\\nEvaluation Metrics:\")\n",
    "        print(f\"Average Accuracy: {evaluation_metrics['average_accuracy']:.2f}\")\n",
    "        print(f\"Average BLEU Score: {evaluation_metrics['average_bleu_score']:.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during evaluation: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db935c1-3de3-418e-86f0-35f19b2c2bf2",
   "metadata": {},
   "source": [
    "## 4. Document the Fine-Tuning Process and Results\n",
    "Proper documentation ensures reproducibility and clarity in your fine-tuning workflow. This includes logging the steps taken, parameters used, and results obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb234d7-1152-4de0-87bc-a3ece13e9a95",
   "metadata": {},
   "source": [
    "### a. Log Fine-Tuning Details\n",
    "Save the fine-tuning job details and evaluation metrics to a log file for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c3e67a54-c090-425f-a2b2-d004e7fe5729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning process documented in fine_tuning_log.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def convert_timestamp(timestamp):\n",
    "    if isinstance(timestamp, int):\n",
    "        return datetime.fromtimestamp(timestamp).isoformat()\n",
    "    elif isinstance(timestamp, datetime):\n",
    "        return timestamp.isoformat()\n",
    "    return str(timestamp)\n",
    "\n",
    "fine_tuning_log = {\n",
    "    \"fine_tuning_job_id\": fine_tune_job_id,\n",
    "    \"fine_tuned_model\": fine_tuned_model,\n",
    "    \"status\": status_response.status if status_response else \"Unknown\",\n",
    "    \"created_at\": convert_timestamp(status_response.created_at) if status_response and hasattr(status_response, 'created_at') else datetime.now().isoformat(),\n",
    "    \"parameters\": {\n",
    "        \"base_model\": \"gpt-4o-mini-2024-07-18\",\n",
    "        \"train_file\": train_file,\n",
    "        \"validation_file\": val_file\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add evaluation metrics if they were calculated\n",
    "if 'evaluation_metrics' in locals():\n",
    "    fine_tuning_log[\"evaluation_metrics\"] = {\n",
    "        \"average_accuracy\": evaluation_metrics.get('average_accuracy', 0),\n",
    "        \"average_bleu_score\": evaluation_metrics.get('average_bleu_score', 0)\n",
    "    }\n",
    "\n",
    "# Save the log to a JSON file\n",
    "log_file = \"fine_tuning_log.json\"\n",
    "with open(log_file, \"w\") as f:\n",
    "    json.dump(fine_tuning_log, f, indent=4)\n",
    "\n",
    "print(f\"Fine-tuning process documented in {log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4e9c5f-b929-4746-a108-97284aed7219",
   "metadata": {},
   "source": [
    "### b. Summarize the Fine-Tuning Outcome\n",
    "Provide a concise summary of the fine-tuning process and its results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c5d4c6f6-5a28-4664-8334-83422e5ab564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-Tuning Summary:\n",
      "--------------------\n",
      "Job ID: ftjob-Q0DuBG1ly5K2d2B8hCZnQXC3\n",
      "Model: ft:gpt-4o-mini-2024-07-18:personal::Ae9mdwfc\n",
      "Status: succeeded\n",
      "Created At: 1734132536\n",
      "Evaluation Metrics:\n",
      "- Average Accuracy: 0.00\n",
      "- Average BLEU Score: 0.00\n",
      "Parameters:\n",
      "- Base Model: gpt-4o-mini-2024-07-18\n",
      "- Epochs: 4\n",
      "- Training File: train.jsonl\n",
      "- Validation File: validation.jsonl\n",
      "\n",
      "Fine-tuning summary saved to fine_tuning_summary.txt\n"
     ]
    }
   ],
   "source": [
    "# Default metrics if evaluation hasn't been performed\n",
    "evaluation_metrics = {\n",
    "    'average_accuracy': 0.0,\n",
    "    'average_bleu_score': 0.0\n",
    "}\n",
    "\n",
    "# If you have previously run the evaluation, replace the above with the actual metrics\n",
    "# evaluation_metrics = evaluate_model(fine_tuned_model, val_df)\n",
    "\n",
    "summary = f\"\"\"\n",
    "Fine-Tuning Summary:\n",
    "--------------------\n",
    "Job ID: {fine_tune_job_id}\n",
    "Model: {fine_tuned_model}\n",
    "Status: {getattr(status_response, 'status', 'Unknown') if status_response else 'Unknown'}\n",
    "Created At: {getattr(status_response, 'created_at', 'N/A') if status_response else 'N/A'}\n",
    "Evaluation Metrics:\n",
    "- Average Accuracy: {evaluation_metrics['average_accuracy']:.2f}\n",
    "- Average BLEU Score: {evaluation_metrics['average_bleu_score']:.2f}\n",
    "Parameters:\n",
    "- Base Model: gpt-4o-mini-2024-07-18\n",
    "- Epochs: 4\n",
    "- Training File: {train_file}\n",
    "- Validation File: {val_file}\n",
    "\"\"\"\n",
    "print(summary)\n",
    "# Optionally, save the summary to a text file\n",
    "with open(\"fine_tuning_summary.txt\", \"w\") as f:\n",
    "    f.write(summary)\n",
    "print(\"Fine-tuning summary saved to fine_tuning_summary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c761bf3-2e6c-4e38-b7b9-f982ce206550",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7936828e-f4b9-4605-b28d-42cef6fa244c",
   "metadata": {},
   "source": [
    "## Chatbot with Context Management and Evaluation Metrics\n",
    "\n",
    "### Overview\n",
    "This script implements a chatbot powered by a fine-tuned OpenAI GPT model. It manages dynamic user interactions, evaluates responses using BLEU scores and accuracy, and maintains conversational context for continuity. The chatbot provides a looped interface for real-time user interaction while assessing its performance in generating relevant responses.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "1. **OpenAI Client Initialization**  \n",
    "   - Configures the OpenAI client using an API key retrieved from environment variables. This ensures secure access to the fine-tuned model for generating responses.\n",
    "\n",
    "2. **Dynamic Prompt Generation**  \n",
    "   - Includes a helper function to dynamically format prompts based on input templates and variables. This enables flexible interaction and query customization.\n",
    "\n",
    "3. **Chat Interaction with the Model**  \n",
    "   - Defines a function to interact with the fine-tuned model using the OpenAI API, passing conversational context and configuration parameters like `max_tokens` and `temperature`.\n",
    "\n",
    "4. **BLEU Score Calculation**  \n",
    "   - Implements a function to evaluate the similarity between the model's generated response and an expected completion using the BLEU metric. This assesses the quality of generated outputs.\n",
    "\n",
    "5. **Context Management**  \n",
    "   - Tracks and updates user-specific conversation history in a dictionary. Limits the context length to a predefined number of exchanges to avoid excessive memory usage.\n",
    "\n",
    "6. **Chatbot Interaction Loop**  \n",
    "   - Provides a real-time conversational interface for users. It:\n",
    "     - Accepts user input.\n",
    "     - Manages and updates conversational context.\n",
    "     - Sends prompts to the model for response generation.\n",
    "     - Evaluates responses using BLEU scores and accuracy.\n",
    "     - Displays the generated response and evaluation metrics.\n",
    "\n",
    "7. **Evaluation Metrics**  \n",
    "   - Includes BLEU score to measure response relevance and an accuracy metric for exact match validation. These provide quantitative insights into the chatbot's performance.\n",
    "\n",
    "8. **Run Functionality**  \n",
    "   - Executes the chatbot in an interactive loop when the script is run directly, allowing users to engage with the chatbot and observe its performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a2afa93c-3c01-42ae-99bf-8e20fb0b1d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is ready. Type 'exit' to end the conversation.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Suggest a nature destination in chhattisgarh.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Located in chhattisgarh, udanti wildlife sanctuary is a popular nature destination built in 1983. It is rated 4.1 on Google reviews.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  What is significant about chaubatia gardens in ranikhet?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: For nature experiences in ranikhet, chaubatia gardens is a top choice. Built in 1952, it has a Google review rating of 4.4.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Suggest a recreational destination in gujarat.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Located in gujarat, gir national park is a popular recreational destination built in 1965. It is rated 4.5 on Google reviews.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Which fort in jaipur is worth visiting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Located in jaipur, amber fort is a popular historical destination built in 1592. It is rated 4.6 on Google reviews.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Tell me about victoria memorial in kolkata.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: victoria memorial is a monument in kolkata, built in 1921. It has a Google review rating of 4.6 and is best visited in the afternoon.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Where can I experience shopping significance in gurugram?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: kingdom of dreams is a shopping in gurugram, built in 2009. It has a Google review rating of 4.4 and is best visited in the afternoon.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Where can I experience religious significance in jammu?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Located in jammu, vaishno devi temple is a popular religious destination built in 1986. It is rated 4.8 on Google reviews.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Thanks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: You're welcome! If you have any more questions, feel free to ask.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending the conversation. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# Fine-tuned model name\n",
    "FINE_TUNED_MODEL = fine_tuned_model  # Replace with your fine-tuned model name\n",
    "\n",
    "# Helper function for dynamic prompt generation\n",
    "def generate_prompt(template, **kwargs):\n",
    "    try:\n",
    "        return template.format(**kwargs)\n",
    "    except KeyError as e:\n",
    "        return f\"Error generating prompt: Missing {e.args[0]}\"\n",
    "\n",
    "# Function to interact with the fine-tuned model\n",
    "def chat_with_model(messages, model=FINE_TUNED_MODEL, max_tokens=100):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error communicating with the model: {e}\"\n",
    "\n",
    "# Evaluation metrics: BLEU score\n",
    "def calculate_bleu(reference, candidate):\n",
    "    try:\n",
    "        ref_tokens = word_tokenize(reference.lower())\n",
    "        cand_tokens = word_tokenize(candidate.lower())\n",
    "        return sentence_bleu([ref_tokens], cand_tokens)\n",
    "    except Exception as e:\n",
    "        print(f\"BLEU score calculation error: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "# Context management\n",
    "user_contexts = {}\n",
    "def update_context(user_id, new_message):\n",
    "    if user_id not in user_contexts:\n",
    "        user_contexts[user_id] = []\n",
    "    user_contexts[user_id].append(new_message)\n",
    "    if len(user_contexts[user_id]) > 10:  # Limit context length\n",
    "        user_contexts[user_id].pop(0)\n",
    "    return user_contexts[user_id]\n",
    "\n",
    "# Chatbot interaction loop with evaluation\n",
    "def chat_with_user(user_id=\"default_user\"):\n",
    "    print(\"Chatbot is ready. Type 'exit' to end the conversation.\")\n",
    "    \n",
    "    while True:\n",
    "        user_message = input(\"You: \").strip()\n",
    "        if user_message.lower() == 'exit':\n",
    "            print(\"Ending the conversation. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Update and manage context\n",
    "        context = update_context(user_id, {\"role\": \"user\", \"content\": user_message})\n",
    "        \n",
    "        # Add system instructions if necessary\n",
    "        if len(context) == 1:\n",
    "            context.insert(0, {\"role\": \"system\", \"content\": \"You are a helpful and knowledgeable assistant.\"})\n",
    "        \n",
    "        # Generate response using the fine-tuned model\n",
    "        model_response = chat_with_model(context)\n",
    "        \n",
    "        # Simulate expected completion for evaluation (you can replace this with actual expected outputs)\n",
    "        expected_completion = \"This is the expected response for your validation.\"\n",
    "        \n",
    "        # Evaluate the response\n",
    "        bleu_score = calculate_bleu(expected_completion, model_response)\n",
    "        accuracy = int(model_response.strip().lower() == expected_completion.strip().lower())\n",
    "        \n",
    "        # Add the assistant's response to the context\n",
    "        update_context(user_id, {\"role\": \"assistant\", \"content\": model_response})\n",
    "        \n",
    "        # Display the response and evaluation metrics\n",
    "        print(f\"Chatbot: {model_response}\")\n",
    "\n",
    "# Run the chatbot if executed directly\n",
    "if __name__ == '__main__':\n",
    "    chat_with_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abffdab4-55de-40e4-a243-771ab0a61180",
   "metadata": {},
   "source": [
    "### Purpose\n",
    "This script provides a comprehensive framework for conversational AI systems, integrating fine-tuned language models, context management, and performance evaluation. It is ideal for applications requiring dynamic user interaction and iterative improvement based on evaluation metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
