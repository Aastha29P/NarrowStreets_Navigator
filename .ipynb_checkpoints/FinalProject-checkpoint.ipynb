{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a58af2-5bd8-4b87-9db6-b903239dd1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.8-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pinecone-client\n",
      "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-1.55.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: flask in /opt/anaconda3/lib/python3.12/site-packages (3.0.3)\n",
      "Collecting react\n",
      "  Downloading react-4.3.0.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (3.9.5)\n",
      "Collecting langchain-core<0.4.0,>=0.3.21 (from langchain)\n",
      "  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.145-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.26.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.10.1-py3-none-any.whl.metadata (169 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.7/169.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.32.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /opt/anaconda3/lib/python3.12/site-packages (from pinecone-client) (2024.7.4)\n",
      "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n",
      "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /opt/anaconda3/lib/python3.12/site-packages (from pinecone-client) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from pinecone-client) (4.11.0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /opt/anaconda3/lib/python3.12/site-packages (from pinecone-client) (2.2.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.26.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.7.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /opt/anaconda3/lib/python3.12/site-packages (from flask) (1.6.2)\n",
      "Collecting optional-django==0.3.0 (from react)\n",
      "  Downloading optional-django-0.3.0.tar.gz (9.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (23.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.11-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.27.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting typing-extensions>=3.7.4 (from pinecone-client)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (2.1)\n",
      "Downloading langchain-0.3.8-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.55.0-py3-none-any.whl (389 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.5/389.5 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.7.1-cp312-cp312-macosx_11_0_arm64.whl (304 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.4/304.4 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.145-py3-none-any.whl (310 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.9/310.9 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Downloading pydantic-2.10.1-py3-none-any.whl (455 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.3/455.3 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.27.1-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading orjson-3.10.11-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (266 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.5/266.5 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: react, optional-django\n",
      "  Building wheel for react (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for react: filename=react-4.3.0-py3-none-any.whl size=4845 sha256=6513fa96e8fcd684ec8f4a7c9a3f61f59559d7485c3a94792729a439dc4d4598\n",
      "  Stored in directory: /Users/aasthaprashar/Library/Caches/pip/wheels/fa/6b/93/07294b18ce5a562535d5fd9e147800023a847594c3fa614685\n",
      "  Building wheel for optional-django (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for optional-django: filename=optional_django-0.3.0-py3-none-any.whl size=10536 sha256=b79d6cbf066290b4a82f2152c6fbedaeeb13b8b826edcea5d37980a0ea0ffa14\n",
      "  Stored in directory: /Users/aasthaprashar/Library/Caches/pip/wheels/66/65/18/beaa69a9f14b73f5a0c8cbbc76f60fbdbd5e76becd5f6b45df\n",
      "Successfully built react optional-django\n",
      "Installing collected packages: optional-django, typing-extensions, pinecone-plugin-interface, orjson, jiter, react, pydantic-core, pinecone-plugin-inference, pydantic, pinecone-client, openai, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.14.6\n",
      "    Uninstalling pydantic_core-2.14.6:\n",
      "      Successfully uninstalled pydantic_core-2.14.6\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.5.3\n",
      "    Uninstalling pydantic-2.5.3:\n",
      "      Successfully uninstalled pydantic-2.5.3\n",
      "Successfully installed jiter-0.7.1 langchain-0.3.8 langchain-core-0.3.21 langchain-text-splitters-0.3.2 langsmith-0.1.145 openai-1.55.0 optional-django-0.3.0 orjson-3.10.11 pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0 pinecone-plugin-interface-0.0.7 pydantic-2.10.1 pydantic-core-2.27.1 react-4.3.0 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain pinecone-client openai flask react\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ace249-76f2-41c6-a287-63d00cddb4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c512e5ee-ac8e-490b-b04a-ef71c0f617a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d039449-ac3e-4956-a2d1-76f96c98903e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Pinecone index: indian-tourist-destinations\n",
      "Top results:\n",
      "6 Lotus Temple 0.894415319\n",
      "0 India Gate 0.892378926\n",
      "5 Chandni Chowk 0.891631842\n",
      "3 Waste to Wonder Park 0.883152306\n",
      "8 Agrasen ki Baoli 0.882829487\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Set up API keys\n",
    "openai_api_key = \"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\"  # Replace with your OpenAI key\n",
    "pinecone_api_key = \"pcsk_3DWssQ_Snki6xhka6gTHhyNMxRNVQvu1zfnihLRFDcNqXvZTys74o54CZsoWXgqGVyvus2\"  # Replace with your Pinecone API key\n",
    "pinecone_environment = \"us-east-1\"  # Replace with your Pinecone environment region\n",
    "\n",
    "# Set the OpenAI API key in the environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "# Create a Pinecone instance\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "# Check if the index exists; if not, create one\n",
    "index_name = \"indian-tourist-destinations\"\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # Example dimension for OpenAI embeddings\n",
    "        metric=\"cosine\",  # Metric to measure similarity\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=pinecone_environment)\n",
    "    )\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Debug: Ensure `index` is not None\n",
    "if index is None:\n",
    "    raise ValueError(\"Failed to initialize or connect to Pinecone index.\")\n",
    "\n",
    "print(f\"Connected to Pinecone index: {index_name}\")\n",
    "\n",
    "# Load your CSV data\n",
    "file_path = \"Top_Indian_Places_to_Visit.csv\"  # Replace with the actual CSV file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Combine relevant columns into a single text representation\n",
    "df[\"combined_text\"] = df.apply(\n",
    "    lambda row: f\"{row['Zone']}, {row['State']}, {row['City']}, {row['Name']}, {row['Type']}, {row['Significance']}, Best time to visit: {row['Best Time to visit']}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Create embeddings for the data and upload to Pinecone\n",
    "embeddings = OpenAIEmbeddings()  # Automatically picks up the API key from the environment\n",
    "for i, row in df.iterrows():\n",
    "    text = row[\"combined_text\"]\n",
    "    embedding = embeddings.embed_query(text)\n",
    "    index.upsert([\n",
    "        {\"id\": str(i), \"values\": embedding, \"metadata\": {\"name\": row[\"Name\"]}}  # Format for Pinecone upsert\n",
    "    ])\n",
    "\n",
    "# Retrieval function\n",
    "def retrieve_relevant_data(user_query):\n",
    "    query_embedding = embeddings.embed_query(user_query)  # Create the query embedding\n",
    "    results = index.query(\n",
    "        vector=query_embedding,  # Use the query embedding\n",
    "        top_k=5,                # Number of top matches to retrieve\n",
    "        include_metadata=True   # Include metadata in the results\n",
    "    )\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "user_query = \"Best places to visit in Delhi during the evening\"\n",
    "results = retrieve_relevant_data(user_query)\n",
    "\n",
    "# Display the results\n",
    "print(\"Top results:\")\n",
    "for result in results[\"matches\"]:\n",
    "    destination_name = result[\"metadata\"][\"name\"]  # Retrieve the destination name\n",
    "    print(result['id'], destination_name, result['score'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "092f290a-68e8-4b7b-8fc5-3383895bf6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matches': [{'id': '306', 'score': -0.0225317683, 'values': []},\n",
      "             {'id': '84', 'score': -0.022840241, 'values': []},\n",
      "             {'id': '35', 'score': -0.0235767569, 'values': []},\n",
      "             {'id': '221', 'score': -0.0238955934, 'values': []},\n",
      "             {'id': '188', 'score': -0.0239897612, 'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n"
     ]
    }
   ],
   "source": [
    "test_query = [0.1] * 1536  # Mock query vector of appropriate dimension\n",
    "test_results = index.query(vector=test_query, top_k=5, include_metadata=True)\n",
    "print(test_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dddff1-b022-44e1-818b-0314117268db",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffe5c9f-ec96-487e-8e7f-603816890f52",
   "metadata": {},
   "source": [
    "Creating Json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eeef11d9-53d4-4abd-a7f7-9492047f8fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Varied JSON data has been written to output.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = \"Top_Indian_Places_to_Visit.csv\"  # Replace with your actual file path\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "# Define prompt and completion templates\n",
    "prompt_templates = [\n",
    "    \"Tell me about {Name} in {City}.\",\n",
    "    \"What is significant about {Name} in {City}?\",\n",
    "    \"Where can I experience {Significance} significance in {City}?\",\n",
    "    \"Which {Type} in {City} is worth visiting?\",\n",
    "    \"What makes {Name} in {City} special?\",\n",
    "    \"Suggest a {Significance} destination in {State}.\",\n",
    "]\n",
    "\n",
    "completion_templates = [\n",
    "    \"{Name} is a {Type} in {City}, built in {Establishment Year}. It has a Google review rating of {Google review rating} and is best visited in the {Best Time to visit}.\",\n",
    "    \"{Name} in {City} is known for its {Significance}. It was established in {Establishment Year} and has a rating of {Google review rating}. Ideal visit time: {Best Time to visit}.\",\n",
    "    \"For {Significance} experiences in {City}, {Name} is a top choice. Built in {Establishment Year}, it has a Google review rating of {Google review rating}.\",\n",
    "    \"{Name} in {City} is a {Type} rated {Google review rating} on Google. It's best visited in the {Best Time to visit}.\",\n",
    "    \"Located in {City}, {Name} is a popular {Significance} destination built in {Establishment Year}. It is rated {Google review rating} on Google reviews.\",\n",
    "]\n",
    "\n",
    "# Function to create varied prompts and completions\n",
    "# Function to create varied prompts and completions\n",
    "def create_varied_prompt_completion(row):\n",
    "    # Safely access and preprocess row data\n",
    "    row_data = {col: (str(row[col]).strip() if pd.notna(row[col]) else \"\") for col in data.columns}\n",
    "    row_data = {k: v.lower() if isinstance(v, str) else v for k, v in row_data.items()}  # Convert strings to lowercase safely\n",
    "    try:\n",
    "        prompt = random.choice(prompt_templates).format(**row_data)\n",
    "        completion = random.choice(completion_templates).format(**row_data)\n",
    "    except KeyError as e:\n",
    "        # Handle missing columns gracefully\n",
    "        print(f\"KeyError: Missing data for {e}\")\n",
    "        return None\n",
    "    return {\"prompt\": prompt, \"completion\": completion}\n",
    "\n",
    "# Generate prompts and completions\n",
    "json_data = [create_varied_prompt_completion(row) for _, row in data.iterrows()]\n",
    "json_data = [entry for entry in json_data if entry]  # Remove None entries\n",
    "\n",
    "# Save the data to a JSON file\n",
    "output_file = \"output.json\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    for entry in json_data:\n",
    "        file.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(f\"Varied JSON data has been written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85111425-f904-46b7-88a5-4408e07bfa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Verify JSONL file\n",
    "with open(\"output.json\", \"r\") as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            assert \"prompt\" in data and \"completion\" in data, \"Missing required fields\"\n",
    "            assert isinstance(data[\"prompt\"], str) and isinstance(data[\"completion\"], str), \"Fields must be strings\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error in line: {line}\\n{e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe7cb564-37c0-4d88-af85-6a72690ea624",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv output.json output.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f06d0b8c-f3d7-43d8-a179-b1c897b57ecd",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.File, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-proj-RGS1SEY4NfR2DNndiwPoM97Mn9Kq5dyo4PBqIePjJRJDxiIItGlNfxxDB9h-O0CL9RLm9bX1KZT3BlbkFJR6E0NUS2sYGVq4lof15E_WFc88sebK9TQ3dCipXB0qjRUKwqTF1EmBbLoyY1X7j5bI11wZlaIA\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Upload the dataset\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mFile\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      7\u001b[0m     file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      8\u001b[0m     purpose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfine-tune\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     12\u001b[0m fine_tune_response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mFineTuning\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     13\u001b[0m     training_file\u001b[38;5;241m=\u001b[39mresponse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.File, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Upload the dataset\n",
    "response = openai.File.create(\n",
    "    file=open(\"output.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "print(\"File ID:\", response[\"id\"])\n",
    "\n",
    "fine_tune_response = openai.FineTuning.create(\n",
    "    training_file=response[\"id\"],\n",
    "    model=\"gpt-4\"\n",
    ")\n",
    "print(\"Fine-tune ID:\", fine_tune_response[\"id\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5848581-b6ee-48a9-abb1-dbe9bd1a32b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2484041038.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[32], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    openai api fine_tunes.prepare_data -f output.jsonl\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "openai api fine_tunes.prepare_data -f output.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98b1d8e-8604-4d65-ac5f-8776e5454c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai api fine_tunes.create -t \"data_prepared.jsonl\" -m \"davinci\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1511f8cc-2c7a-49f3-a1f2-0846c928a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai api fine_tunes.follow -i <FINE_TUNE_JOB_ID>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc7959b-8365-4dd0-a2bd-7a97e7decb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "    model=\"<your-fine-tuned-model>\",\n",
    "    prompt=\"Best places to visit in Delhi during the evening?\",\n",
    "    max_tokens=50\n",
    ")\n",
    "print(response.choices[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3426f-924b-4a17-9629-1f98ced9faf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e080fa-fc72-4742-a874-043444746af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30b1a49c-3d43-41cc-9bc3-bbd25ad19588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.12/site-packages (1.55.0)\n",
      "Collecting openai\n",
      "  Downloading openai-1.55.3-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (2.10.1)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Downloading openai-1.55.3-py3-none-any.whl (389 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.55.0\n",
      "    Uninstalling openai-1.55.0:\n",
      "      Successfully uninstalled openai-1.55.0\n",
      "Successfully installed openai-1.55.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "394ba889-eeda-43d2-9902-6690559bfb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error uploading file: 'fine_tune' is not one of ['fine-tune', 'assistants', 'batch', 'user_data', 'responses', 'vision', 'evals'] - 'purpose'\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Upload the dataset\n",
    "def upload_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            response = openai.File.create(file=open(\"output.jsonl\", \"rb\"), purpose=\"fine-tune\")\n",
    "\n",
    "        print(\"File uploaded successfully.\")\n",
    "        print(\"File ID:\", response[\"id\"])\n",
    "        return response[\"id\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error uploading file:\", e)\n",
    "        return None\n",
    "\n",
    "# Start the fine-tuning process\n",
    "def start_fine_tuning(training_file_id, model=\"gpt-4\"):\n",
    "    try:\n",
    "        fine_tune_response = openai.FineTuning.create(\n",
    "            training_file=training_file_id,\n",
    "            model=model\n",
    "        )\n",
    "        print(\"Fine-tuning started.\")\n",
    "        print(\"Fine-tune ID:\", fine_tune_response[\"id\"])\n",
    "        return fine_tune_response[\"id\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error starting fine-tuning:\", e)\n",
    "        return None\n",
    "\n",
    "# Check the status of fine-tuning\n",
    "def check_fine_tune_status(fine_tune_id):\n",
    "    try:\n",
    "        status_response = openai.FineTuning.retrieve(id=fine_tune_id)\n",
    "        print(\"Fine-tune status:\")\n",
    "        print(status_response)\n",
    "        return status_response\n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving fine-tune status:\", e)\n",
    "        return None\n",
    "\n",
    "# Use the fine-tuned model\n",
    "def use_fine_tuned_model(model_name, prompt):\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=model_name,\n",
    "            prompt=prompt,\n",
    "            max_tokens=100,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        print(\"Generated response:\")\n",
    "        print(response.choices[0].text.strip())\n",
    "    except Exception as e:\n",
    "        print(\"Error using the fine-tuned model:\", e)\n",
    "\n",
    "# Main workflow\n",
    "def main():\n",
    "    # Step 1: Upload file\n",
    "    file_path = \"output.jsonl\"  # Replace with your actual JSONL file path\n",
    "    training_file_id = upload_file(file_path)\n",
    "\n",
    "    if not training_file_id:\n",
    "        return\n",
    "\n",
    "    # Step 2: Start fine-tuning\n",
    "    fine_tune_id = start_fine_tuning(training_file_id, model=\"gpt-4\")\n",
    "\n",
    "    if not fine_tune_id:\n",
    "        return\n",
    "\n",
    "    # Step 3: Monitor fine-tuning\n",
    "    print(\"Monitoring fine-tuning process. This may take some time...\")\n",
    "    import time\n",
    "    while True:\n",
    "        status = check_fine_tune_status(fine_tune_id)\n",
    "        if status and status[\"status\"] == \"succeeded\":\n",
    "            print(\"Fine-tuning completed successfully.\")\n",
    "            fine_tuned_model = status[\"fine_tuned_model\"]\n",
    "            break\n",
    "        elif status and status[\"status\"] == \"failed\":\n",
    "            print(\"Fine-tuning failed. Check the logs for more details.\")\n",
    "            return\n",
    "        time.sleep(60)  # Check every minute\n",
    "\n",
    "    # Step 4: Use the fine-tuned model\n",
    "    prompt = \"Tell me about India Gate in Delhi.\"\n",
    "    use_fine_tuned_model(fine_tuned_model, prompt)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8010795e-3185-4d44-8575-64a0b76f06d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.27.8\n",
      "  Downloading openai-0.27.8-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/anaconda3/lib/python3.12/site-packages (from openai==0.27.8) (2.32.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from openai==0.27.8) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from openai==0.27.8) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai==0.27.8) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai==0.27.8) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai==0.27.8) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai==0.27.8) (2024.8.30)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.27.8) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.27.8) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.27.8) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.27.8) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.27.8) (1.9.3)\n",
      "Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.0\n",
      "    Uninstalling openai-0.28.0:\n",
      "      Successfully uninstalled openai-0.28.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.2.9 requires openai<2.0.0,>=1.54.0, but you have openai 0.27.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed openai-0.27.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.27.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035f8fc8-2d45-46d4-97f6-72a830916ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error starting fine-tuning: Object of type BufferedReader is not JSON serializable\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Prepare the fine-tuning job\n",
    "def start_fine_tuning(file_path, model=\"gpt-3.5-turbo\"):\n",
    "    try:\n",
    "        # Open the JSONL file\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            fine_tune_response = openai.FineTuningJob.create(\n",
    "                training_file=file,\n",
    "                model=model\n",
    "            )\n",
    "        print(\"Fine-tuning job created successfully.\")\n",
    "        print(\"Fine-tune Job ID:\", fine_tune_response[\"id\"])\n",
    "        return fine_tune_response[\"id\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error starting fine-tuning:\", e)\n",
    "        return None\n",
    "\n",
    "# Monitor the fine-tuning job\n",
    "def check_fine_tune_status(fine_tune_id):\n",
    "    try:\n",
    "        status_response = openai.FineTuningJob.retrieve(id=fine_tune_id)\n",
    "        print(\"Fine-tune status:\")\n",
    "        print(status_response)\n",
    "        return status_response\n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving fine-tune status:\", e)\n",
    "        return None\n",
    "\n",
    "# Use the fine-tuned model\n",
    "def use_fine_tuned_model(model_name, prompt):\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=model_name,\n",
    "            prompt=prompt,\n",
    "            max_tokens=100,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        print(\"Generated response:\")\n",
    "        print(response.choices[0].text.strip())\n",
    "    except Exception as e:\n",
    "        print(\"Error using the fine-tuned model:\", e)\n",
    "\n",
    "# Main workflow\n",
    "def main():\n",
    "    # Path to your JSONL file\n",
    "    file_path = \"output.jsonl\"  # Replace with your actual JSONL file path\n",
    "\n",
    "    # Step 1: Start fine-tuning\n",
    "    fine_tune_id = start_fine_tuning(file_path, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "    if not fine_tune_id:\n",
    "        return\n",
    "\n",
    "    # Step 2: Monitor fine-tuning\n",
    "    print(\"Monitoring fine-tuning process. This may take some time...\")\n",
    "    import time\n",
    "    while True:\n",
    "        status = check_fine_tune_status(fine_tune_id)\n",
    "        if status and status[\"status\"] == \"succeeded\":\n",
    "            print(\"Fine-tuning completed successfully.\")\n",
    "            fine_tuned_model = status[\"fine_tuned_model\"]\n",
    "            break\n",
    "        elif status and status[\"status\"] == \"failed\":\n",
    "            print(\"Fine-tuning failed. Check the logs for more details.\")\n",
    "            return\n",
    "        time.sleep(60)  # Check every minute\n",
    "\n",
    "    # Step 3: Use the fine-tuned model\n",
    "    prompt = \"Tell me about India Gate in Delhi.\"\n",
    "    use_fine_tuned_model(fine_tuned_model, prompt)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26157bd7-7677-482a-8102-dd8355d6979b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
