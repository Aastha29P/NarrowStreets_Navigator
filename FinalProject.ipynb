{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "075a949a-a50f-4a0f-bc1d-0fd189637dca",
   "metadata": {},
   "source": [
    "# NarrowStreets Navigator: AI- Generated Personalized Travel Itineraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cab0f23-4664-4e32-9046-5a638479aaee",
   "metadata": {},
   "source": [
    "By Aastha Prashar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1b2e2c-e89f-4d97-b052-0aafe8eb9f3b",
   "metadata": {},
   "source": [
    "#### This project aims to create an AI-powered travel assistant that generates highly personalized travel itineraries tailored to user preferences such as budget, available time, desired activities, and specific locations. By integrating Retrieval-Augmented Generation (RAG), Fine-tuning, and Prompt Engineering, the system will provide intelligent and dynamic recommendations that adapt to user interactions in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c512e5ee-ac8e-490b-b04a-ef71c0f617a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain pinecone-client openai flask react"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f1154c-9eec-4321-936c-2f82a75d13bc",
   "metadata": {},
   "source": [
    "### Integrating Pinecone with OpenAI Embeddings for Data Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fd9f93-2ff2-400d-af5d-aab4eedb84e5",
   "metadata": {},
   "source": [
    "This script demonstrates how to use Pinecone and OpenAI Embeddings to create a search engine for tourist destinations in India. It processes data from a CSV file, generates embeddings, and stores them in a Pinecone index to allow efficient semantic search. Below is a detailed explanation of the steps and code structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d039449-ac3e-4956-a2d1-76f96c98903e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Pinecone index: indian-tourist-destinations\n",
      "Top results:\n",
      "4 Jantar Mantar 0.900983095\n",
      "10 Garden of Five Senses 0.895219922\n",
      "318 Rail Museum 0.893747509\n",
      "5 Chandni Chowk 0.88187921\n",
      "14 Qutub Minar 0.879444361\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Set up API keys\n",
    "openai_api_key = \"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\"  # Replace with your OpenAI key\n",
    "pinecone_api_key = \"pcsk_3DWssQ_Snki6xhka6gTHhyNMxRNVQvu1zfnihLRFDcNqXvZTys74o54CZsoWXgqGVyvus2\"  # Replace with your Pinecone API key\n",
    "pinecone_environment = \"us-east-1\"  # Replace with your Pinecone environment region\n",
    "\n",
    "# Set the OpenAI API key in the environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "# Create a Pinecone instance\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "# Check if the index exists; if not, create one\n",
    "index_name = \"indian-tourist-destinations\"\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # Example dimension for OpenAI embeddings\n",
    "        metric=\"cosine\",  # Metric to measure similarity\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=pinecone_environment)\n",
    "    )\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Debug: Ensure `index` is not None\n",
    "if index is None:\n",
    "    raise ValueError(\"Failed to initialize or connect to Pinecone index.\")\n",
    "\n",
    "print(f\"Connected to Pinecone index: {index_name}\")\n",
    "\n",
    "# Load your CSV data\n",
    "file_path = \"Top_Indian_Places_to_Visit.csv\"  # Replace with the actual CSV file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Combine relevant columns into a single text representation\n",
    "df[\"combined_text\"] = df.apply(\n",
    "    lambda row: f\"{row['Zone']}, {row['State']}, {row['City']}, {row['Name']}, {row['Type']}, {row['Significance']}, Best time to visit: {row['Best Time to visit']}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Create embeddings for the data and upload to Pinecone\n",
    "embeddings = OpenAIEmbeddings()  # Automatically picks up the API key from the environment\n",
    "for i, row in df.iterrows():\n",
    "    text = row[\"combined_text\"]\n",
    "    embedding = embeddings.embed_query(text)\n",
    "    index.upsert([\n",
    "        {\"id\": str(i), \"values\": embedding, \"metadata\": {\"name\": row[\"Name\"]}}  # Format for Pinecone upsert\n",
    "    ])\n",
    "\n",
    "# Retrieval function\n",
    "def retrieve_relevant_data(user_query):\n",
    "    query_embedding = embeddings.embed_query(user_query)  # Create the query embedding\n",
    "    results = index.query(\n",
    "        vector=query_embedding,  # Use the query embedding\n",
    "        top_k=5,                # Number of top matches to retrieve\n",
    "        include_metadata=True   # Include metadata in the results\n",
    "    )\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "user_query = \"Best places to visit in Delhi during the morning\"\n",
    "results = retrieve_relevant_data(user_query)\n",
    "\n",
    "# Display the results\n",
    "print(\"Top results:\")\n",
    "for result in results[\"matches\"]:\n",
    "    destination_name = result[\"metadata\"][\"name\"]  # Retrieve the destination name\n",
    "    print(result['id'], destination_name, result['score'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d197221-3b3f-4f70-a3db-3d52d222d110",
   "metadata": {},
   "source": [
    "# Explanation Points\n",
    "\n",
    "### 1. Setup and API Configuration  \n",
    "- The script begins by importing necessary libraries and setting up API keys for OpenAI and Pinecone. These keys are used to access their respective services.\n",
    "\n",
    "### 2. Pinecone Initialization  \n",
    "- A Pinecone instance is initialized using the API key and environment details. The script checks if an index exists and creates one if necessary. The index is configured to use cosine similarity for embedding comparisons.\n",
    "\n",
    "### 3. Data Preparation  \n",
    "- A CSV file containing details about Indian tourist destinations is loaded, and relevant columns are combined into a single text representation to form the basis for embeddings.\n",
    "\n",
    "### 4. Generating and Storing Embeddings  \n",
    "- Text embeddings are generated using OpenAI's embedding model and stored in the Pinecone index, along with metadata for each destination.\n",
    "\n",
    "### 5. Semantic Search Function  \n",
    "- A function is defined to retrieve the most relevant results based on a user query. The query is embedded and compared against stored embeddings in the Pinecone index.\n",
    "\n",
    "### 6. Example Query  \n",
    "- The script provides an example query to retrieve relevant tourist destinations based on user input, showcasing the functionality of the semantic search engine.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Features\n",
    "- **Embedding Generation**: Converts textual data into high-dimensional vectors for semantic understanding.  \n",
    "- **Efficient Indexing**: Utilizes Pinecone for scalable and fast search operations.  \n",
    "- **Dynamic Queries**: Supports user-defined queries to retrieve contextually relevant results.\n",
    "\n",
    "---\n",
    "\n",
    "## Applications\n",
    "This script can be extended to build:  \n",
    "- **Personalized Travel Recommendation Engines**  \n",
    "- **Content-based Search Engines**  \n",
    "- **Contextual Data Analysis Systems**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b695ab13-89ba-428f-8c3f-a2165d3280cc",
   "metadata": {},
   "source": [
    "# Querying the Pinecone Index with a Test Vector\n",
    "\n",
    "### Overview\n",
    "This snippet demonstrates how to perform a test query on the Pinecone index using a mock vector. A query vector of appropriate dimension is created, and the `query` method of the Pinecone index is used to retrieve the top 5 most relevant matches. The results include metadata associated with the stored embeddings, providing insights into the retrieved items.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "092f290a-68e8-4b7b-8fc5-3383895bf6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matches': [{'id': '35',\n",
      "              'metadata': {'name': 'Ramoji Film City'},\n",
      "              'score': -0.0256339014,\n",
      "              'values': []},\n",
      "             {'id': '177',\n",
      "              'metadata': {'name': 'Jim Corbett National Park'},\n",
      "              'score': -0.0257302076,\n",
      "              'values': []},\n",
      "             {'id': '84',\n",
      "              'metadata': {'name': 'Ajmer Sharif Dargah'},\n",
      "              'score': -0.0257691536,\n",
      "              'values': []},\n",
      "             {'id': '106',\n",
      "              'metadata': {'name': 'Kovalam Beach'},\n",
      "              'score': -0.0258768685,\n",
      "              'values': []},\n",
      "             {'id': '92',\n",
      "              'metadata': {'name': 'Golden Temple (Harmandir Sahib)'},\n",
      "              'score': -0.0259095058,\n",
      "              'values': []}],\n",
      " 'namespace': '',\n",
      " 'usage': {'read_units': 6}}\n"
     ]
    }
   ],
   "source": [
    "test_query = [0.1] * 1536  # Mock query vector of appropriate dimension\n",
    "test_results = index.query(vector=test_query, top_k=5, include_metadata=True)\n",
    "print(test_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fd8b66-650f-4d18-9b1b-40187246dd48",
   "metadata": {},
   "source": [
    "### Explanation of Output\n",
    "\n",
    "The output represents the results of a query performed on the Pinecone index. Here's a breakdown of its key components:\n",
    "\n",
    "1. **`matches`**  \n",
    "   - Contains a list of the top 5 results retrieved from the index. Each match includes the following details:\n",
    "     - **`id`**: The unique identifier of the record in the index.\n",
    "     - **`metadata`**: Metadata associated with the record, such as the name of the location.\n",
    "     - **`score`**: A similarity score indicating how well the query matches the indexed record. Lower (negative) values suggest a higher similarity.\n",
    "     - **`values`**: An empty list in this case, as the actual embedding values are not returned.\n",
    "\n",
    "2. **`namespace`**  \n",
    "   - Represents the namespace in which the query was executed. In this case, it is empty, indicating that the default namespace was used.\n",
    "\n",
    "3. **`usage`**  \n",
    "   - Shows resource usage information. For this query, `read_units` indicates that 6 units of read capacity were consumed.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Insights\n",
    "- The retrieved results include metadata like the names of popular locations (e.g., \"Ramoji Film City\" and \"Golden Temple\").\n",
    "- The similarity scores allow ranking the results, with closer matches appearing higher in the list.\n",
    "- The absence of values suggests this query is focused on metadata and similarity scores rather than retrieving the full embedding vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffe5c9f-ec96-487e-8e7f-603816890f52",
   "metadata": {},
   "source": [
    "# Generating JSON Messages from CSV Data for a Conversational Guide\n",
    "\n",
    "### Overview\n",
    "This script processes data from a CSV file containing information about Indian tourist destinations and converts it into JSON format for use in a conversational system. The system generates prompts and responses dynamically, creating engaging and informative dialogues about attractions in different cities.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Breakdown\n",
    "\n",
    "1. **Loading Data**  \n",
    "   - The script reads the CSV file, which contains details like attraction names, cities, states, significance, and other relevant metadata.\n",
    "\n",
    "2. **Prompt and Completion Templates**  \n",
    "   - Predefined templates for user prompts and assistant completions are defined. These templates are dynamically populated with data from the CSV to generate realistic and contextually appropriate dialogues.\n",
    "\n",
    "3. **Message Creation Function**  \n",
    "   - For each row in the CSV:\n",
    "     - A random prompt and completion template are selected and formatted with the row's data.\n",
    "     - A system message is created to provide context about the city.\n",
    "     - The messages are structured into a JSON object with roles (`system`, `user`, and `assistant`) to align with conversational AI frameworks.\n",
    "\n",
    "4. **Error Handling**  \n",
    "   - KeyErrors are handled gracefully by checking for missing data and skipping rows that cannot be processed.\n",
    "\n",
    "5. **Saving JSON Data**  \n",
    "   - The generated messages are saved in JSON format, one object per line, in the specified output file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeef11d9-53d4-4abd-a7f7-9492047f8fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted JSON data has been written to output.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = \"Top_Indian_Places_to_Visit.csv\"  # Replace with your actual file path\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "# Define prompt and completion templates\n",
    "prompt_templates = [\n",
    "    \"Tell me about {Name} in {City}.\",\n",
    "    \"What is significant about {Name} in {City}?\",\n",
    "    \"Where can I experience {Significance} significance in {City}?\",\n",
    "    \"Which {Type} in {City} is worth visiting?\",\n",
    "    \"What makes {Name} in {City} special?\",\n",
    "    \"Suggest a {Significance} destination in {State}.\",\n",
    "]\n",
    "\n",
    "completion_templates = [\n",
    "    \"{Name} is a {Type} in {City}, built in {Establishment Year}. It has a Google review rating of {Google review rating} and is best visited in the {Best Time to visit}.\",\n",
    "    \"{Name} in {City} is known for its {Significance}. It was established in {Establishment Year} and has a rating of {Google review rating}. Ideal visit time: {Best Time to visit}.\",\n",
    "    \"For {Significance} experiences in {City}, {Name} is a top choice. Built in {Establishment Year}, it has a Google review rating of {Google review rating}.\",\n",
    "    \"{Name} in {City} is a {Type} rated {Google review rating} on Google. It's best visited in the {Best Time to visit}.\",\n",
    "    \"Located in {City}, {Name} is a popular {Significance} destination built in {Establishment Year}. It is rated {Google review rating} on Google reviews.\",\n",
    "]\n",
    "\n",
    "# Function to create messages in the desired JSON format\n",
    "def create_messages(row):\n",
    "    # Safely access and preprocess row data\n",
    "    row_data = {col: (str(row[col]).strip() if pd.notna(row[col]) else \"\") for col in data.columns}\n",
    "    # Convert strings to lowercase to match the example format\n",
    "    row_data = {k: v.lower() if isinstance(v, str) else v for k, v in row_data.items()}\n",
    "    \n",
    "    try:\n",
    "        # Select random prompt and completion templates\n",
    "        prompt = random.choice(prompt_templates).format(**row_data)\n",
    "        completion = random.choice(completion_templates).format(**row_data)\n",
    "        \n",
    "        # Create the system message based on the City\n",
    "        system_content = f\"You are a helpful guide about {row_data['City']} attractions.\"\n",
    "        \n",
    "        # Structure the messages as required\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": completion}\n",
    "        ]\n",
    "        \n",
    "        return {\"messages\": messages}\n",
    "    \n",
    "    except KeyError as e:\n",
    "        # Handle missing columns gracefully\n",
    "        print(f\"KeyError: Missing data for {e}\")\n",
    "        return None\n",
    "\n",
    "# Generate messages for each row in the CSV\n",
    "json_data = [create_messages(row) for _, row in data.iterrows()]\n",
    "# Remove any None entries resulting from KeyErrors\n",
    "json_data = [entry for entry in json_data if entry]\n",
    "\n",
    "# Save the data to a JSON file, one JSON object per line\n",
    "output_file = \"output.json\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    for entry in json_data:\n",
    "        file.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(f\"Formatted JSON data has been written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63379bc8-4481-47e6-b3b6-695db58ca1f7",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "This script is a robust tool for creating conversational data from structured input. By using templates and dynamically filling them with data, it enables the creation of diverse and contextually rich messages. The output JSON can be used in chatbots or other conversational AI systems to provide information about tourist destinations in a natural and engaging way. The system ensures reliability by handling missing data and maintaining the integrity of the output file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ef8cd2-643d-40aa-8629-f6e02d844c6d",
   "metadata": {},
   "source": [
    "#### Converting the generated output.json file to output.jsonl file. This .jsonl is a format where each line in the file is a separate, valid JSON object. It is commonly used for processing large datasets, as each JSON object can be read line-by-line without loading the entire file into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe7cb564-37c0-4d88-af85-6a72690ea624",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv output.json output.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db170d81-0ee2-4e11-9d3c-d17d2577a165",
   "metadata": {},
   "source": [
    "This script securely loads API keys and environment variables from a .env file using the dotenv library. It retrieves variables like OPENAI_API_KEY, PINECONE_API_KEY, and PINECONE_ENVIRONMENT with os.getenv(), allowing sensitive data to be managed outside the codebase for enhanced security and flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "096d5aaa-bffa-4e7c-95d8-0f2a3073dd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: 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\n",
      "Pinecone API Key: pcsk_3DWssQ_Snki6xhka6gTHhyNMxRNVQvu1zfnihLRFDcNqXvZTys74o54CZsoWXgqGVyvus2\n",
      "Pinecone Environment: None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load variables from .env file into environment\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the variables\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pinecone_environment = os.getenv(\"PINECONE_ENVIRONMENT\")\n",
    "\n",
    "# Verify that the variables are loaded (optional)\n",
    "print(f\"OpenAI API Key: {openai_api_key}\")\n",
    "print(f\"Pinecone API Key: {pinecone_api_key}\")\n",
    "print(f\"Pinecone Environment: {pinecone_environment}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
